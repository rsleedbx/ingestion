{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15a3e62d-a594-4d8e-b979-55f5d7162955",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Overview\n",
    "This demo environment is designed to help answer the following questions:\n",
    "- How does it work\n",
    "- How fast is snapshot (bulk insert) performance\n",
    "- How fast is realtime (CDC) performance\n",
    "\n",
    "Demo is not for for:\n",
    "- Schema and data type validation\n",
    "- Tuning based on environmental factors\n",
    "- Data value conversion\n",
    "- HA and resilience testing \n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Click `Run All`\n",
    "2. SQL Server to Null \n",
    "   1. Enter `Arcion License`\n",
    "   2. Look at snapshot performance\n",
    "   3. Look at cdc performance\n",
    "3. SQL Serer to Deltalake  \n",
    "   1. Enter Access Token\n",
    "   2. Click `Deltalake` target\n",
    "   3. Click `Run All`\n",
    "   4. Look at snapshot performance\n",
    "   5. Look at cdc performance\n",
    "   \n",
    "## Demo Environment\n",
    "\n",
    "### Infrastructures\n",
    "\n",
    "The following the demo environment.\n",
    "```text\n",
    "  +--------------Databricks Personal Compute Cluster--------------------------+  \n",
    "  |  +-----------+    +-----------+          +----------+     +------------+  |\n",
    "  |  |  Workload |    | Source DB |          |  Arcion  |     | Target DB  |  | \n",
    "  |  |           |    |           | <--------|          |     |            |  |\n",
    "  |  |   YCSB    | -->| SQL Server|          | Notebook | --> | Databricks |  |\n",
    "  |  |           |    |           | -------->|   CLI    |     |            |  |\n",
    "  |  +-----------+    +-----------+          +----------+     +------------+  |\n",
    "  +---------------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "In the production, the following is expected separation.\n",
    "```text\n",
    "  +----------Customer Cloud---------+   F   +---- Databricks Serverless ------+  \n",
    "  |  +-----------+    +-----------+ |   I   | +----------+     +------------+ |\n",
    "  |  |  Workload |    | Source DB | |   R   | |  Arcion  |     | Target DB  | | \n",
    "  |  |           |    |           | | <-E-- | |          |     |            | |\n",
    "  |  |   YCSB    | -->| SQL Server| |   W   | | Notebook | --> | Databricks | |\n",
    "  |  |           |    |           | | --A-> | |    UI    |     |            | |\n",
    "  |  +-----------+    +-----------+ |   L   | +----------+     +------------+ |  \n",
    "  +---------------------------------+   L   +---------------------------------+\n",
    "```\n",
    "\n",
    "### Schema \n",
    "\n",
    "In the demo, there are dense and sparse tables.\n",
    "Dense and sparse tables try to model a star schema.\n",
    "Dense tables can be long and wide and have most of the fields populated.\n",
    "Sparse tables can be short and wide if required and have most of the fields NOT populated.\n",
    "\n",
    "- An arbitrary number of dense and sparse tables be defined.  \n",
    "- Each table can have defined number of fields.  \n",
    "- Range of populated fields can be defined.\n",
    "- A specified number of records are inserted/appended using native bulk copy.  \n",
    "\n",
    "Dense tables have all fields populated to data to the max length of the field.\n",
    "Sparse tables fields are populated with NULLs.\n",
    "\n",
    "```text\n",
    "+--------+    +--------+  +--------+    +--------+\n",
    "| Dense  |    | Dense  |  | Sparse |    | Sparse | \n",
    "| Tables | ...| Tables |  | Tables | ...| Tables |\n",
    "|   1    |    |   n    |  |   1    |    |    n   |\n",
    "+--------+    +--------+  +--------+    +--------+\n",
    "```\n",
    "\n",
    "Dense and sparse tables allow one to model capacity and performance of:\n",
    "- Star schema\n",
    "- IOT data \n",
    "- big data\n",
    "\n",
    "### Workload\n",
    "\n",
    "Workload uses [customized](https://github.com/arcionlabs/YCSB/tree/jdbc_url_delim) Yahoo Cloud Services Benchmark [YCSB](https://github.com/brianfrankcooper/YCSB).\n",
    "\n",
    "### Arcion\n",
    "\n",
    "Legacy Arcion CLI is used.\n",
    "\n",
    "### Staging\n",
    "\n",
    "#### DBFS\n",
    "\n",
    "The root directory will be created if does not exist.\n",
    "can be access under /dbfs/<root dir name>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fd45e92-ead4-45c5-be8f-6a0bb78534f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Install Arcion, YCSB and SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9cca325-b2f8-4be4-aaf6-862be36fe237",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# prep python env\n",
    "import subprocess\n",
    "import math\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox, Label\n",
    "\n",
    "# setup GUI elements\n",
    "\n",
    "repl_mode = widgets.Dropdown(options=['snapshot', 'real-time', 'full'],value='snapshot',\n",
    "    description='Replication:',\n",
    ")\n",
    "cdc_mode = widgets.Dropdown(options=['change', 'cdc'],value='change',\n",
    "    description='CDC Method:',\n",
    ")\n",
    "\n",
    "snapshot_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Snapshot Threads:',\n",
    ")\n",
    "\n",
    "realtime_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Real Time Threads:',\n",
    ")    \n",
    "\n",
    "delta_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Delta Snapshot Threads:',\n",
    ")    \n",
    "\n",
    "dbx_destinations = widgets.Dropdown(options=['null', 'deltalake', 'unitycatalog'],value='null',\n",
    "    description='Destinations:',\n",
    ")\n",
    "dbx_staging = widgets.Dropdown(options=['dbfs'],value='dbfs',\n",
    "    description='Staging:',\n",
    ")\n",
    "\n",
    "sparse_cnt = widgets.BoundedIntText(value=1,min=1,max=100,\n",
    "    description='Table Cnt:',\n",
    ")\n",
    "sparse_fieldcount = widgets.BoundedIntText(value=50,min=0,max=9000,\n",
    "    description='# of Fields:',\n",
    ")\n",
    "sparse_fieldlength = widgets.BoundedIntText(value=10,min=1,max=1000,\n",
    "    description='Field Len:',\n",
    ")\n",
    "\n",
    "sparse_tps = widgets.BoundedIntText(value=1,min=0,max=1000,\n",
    "    description='TPS:',\n",
    ")\n",
    "sparse_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Threads:',\n",
    ")\n",
    "sparse_recordcount = widgets.Text(value=\"1M\",\n",
    "    description='Rec Cnt:',\n",
    ")\n",
    "\n",
    "sparse_fillpct = widgets.IntRangeSlider(value=[0,0],min=0,max=100,step=1,\n",
    "    description='Fill Range:', orientation='horizontal', readout=False\n",
    ")\n",
    "\n",
    "dense_cnt = widgets.BoundedIntText(value=1,min=1,max=100,\n",
    "    description='Table Cnt:',\n",
    ")\n",
    "dense_fieldcount = widgets.BoundedIntText(value=10,min=0,max=9000,\n",
    "    description='# of Fields:',\n",
    ")\n",
    "dense_fieldlength = widgets.BoundedIntText(value=100,min=1,max=1000,\n",
    "    description='Field Len:',\n",
    ")\n",
    "dense_recordcount = widgets.Text(value=\"100K\",\n",
    "    description='Rec Cnt:',\n",
    ")\n",
    "\n",
    "dense_tps = widgets.BoundedIntText(value=1,min=0,max=1000,\n",
    "    description='TPS:',\n",
    ")\n",
    "dense_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Threads:',\n",
    ")\n",
    "\n",
    "dense_fillpct = widgets.IntRangeSlider(value=[0,100],min=0,max=100,step=1,\n",
    "    description='Fill Range:', orientation='horizontal', readout=False\n",
    ")\n",
    "\n",
    "dbx_spark_url = widgets.Textarea(value='',\n",
    "    description='Spark URL:',\n",
    ")\n",
    "\n",
    "dbx_databricks_url = widgets.Textarea(value='',\n",
    "    description='Databricks URL:',\n",
    ")\n",
    "\n",
    "dbx_hostname = widgets.Textarea(value='',\n",
    "    description='Hostname:',\n",
    ")\n",
    "\n",
    "dbx_username = widgets.Textarea(value='',\n",
    "    description='Username:',\n",
    ")\n",
    "\n",
    "arcion_license = widgets.Textarea(value='',\n",
    "    description='Arcion Lic',\n",
    ")\n",
    "\n",
    "dbx_access_token = widgets.Textarea(value='',\n",
    "    description='Access Token',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c99e039419241da8c56f460ca5bb816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='License'), Textarea(value='', description='Arcion Lic'), Textarea(vâ€¦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter license and DBX personal access token\n",
    "VBox([HBox([Label('License'), arcion_license, dbx_access_token]), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a208371c-d54e-4158-81be-16483107efa0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deltalake /opt/stage/libs/SparkJDBC42.jar found\n",
      "lakehouse  /opt/stage/libs/DatabricksJDBC42.jar found\n",
      "postgres  /opt/stage/libs/postgresql-42.7.1.jar found\n",
      "mariadb  /opt/stage/libs/mariadb-java-client-3.3.2.jar found\n",
      "oracle /opt/stage/libs/ojdbc8.jar found\n",
      "log4j /opt/stage/libs/log4j-1.2.17.jar found\n",
      "arcion  /opt/stage/arcion/replicant-cli/bin/replicant found\n",
      "checking jar(s) in /opt/stage/arcion/24.01.25.1/replicant-cli/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/24.01.25.1/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/replicant-cli/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/replicate-cli-23.05.31.29/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/23.05.31.31/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/24.01.25.7/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/23.09.29.11/lib for updates\n",
      "Arcion license found\n",
      "YCSB  /opt/stage/ycsb/ycsb-jdbc-binding-0.18.0-SNAPSHOT  found\n",
      "numfmt found\n",
      "checking jar(s) in /opt/stage/ycsb/ycsb-jdbc-binding-0.18.0-SNAPSHOT/lib for updates\n",
      "apt-utils already installed\n",
      "mssql-server already installed\n",
      "mssql-tools18 already installed\n",
      "unixodbc-dev alrady installed\n",
      "sqlserver already started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='bin/install-sqlserver.sh', returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup arcion, ycsb, sql server\n",
    "subprocess.run(f\"\"\"bin/download-jars.sh\"\"\",shell=True,executable=\"/usr/bin/bash\")\n",
    "subprocess.run(f\"\"\"ARCION_LICENSE={arcion_license.value} bin/install-arcion.sh\"\"\",shell=True,executable=\"/usr/bin/bash\")\n",
    "subprocess.run(f\"\"\"bin/install-ycsb.sh\"\"\",shell=True,executable=\"/usr/bin/bash\")\n",
    "subprocess.run(f\"\"\"bin/install-sqlserver.sh\"\"\",shell=True,executable=\"/usr/bin/bash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "427dc8c9-96f3-4ac6-bf41-4efd371f3b04",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Customize schema and size\n",
    "\n",
    "Existing tables will be appended with additional rows if the `Fill Range` is the same.  \n",
    "Increase the `Table Count` to create additional tables.  \n",
    "\n",
    "The following options are available:\n",
    "- Table count (Table Cnt): The number of tables to create.  \n",
    "  - Table names are `ycsbdense`, `ycsbdense2`, `ycsbdense3`, ... and `ycssparse`, `ycsbdense2`, and `ycsbdense3` ...\n",
    "- Number of Fields (# of Fields): The number of fields per table.  \n",
    "  - The field names are `FIELD0`, `FIELD1`, `FIELD2`, ...\n",
    "  - Note the use of `K`,`M`,`B` ... suffix at the end.\n",
    "- Field Length (Field Len): The length of random character data populated per field.  \n",
    "  - Note the use of `K`,`M`,`B` ... suffix at the end.\n",
    "- Record Count (Rec Cnt): The number of records per table generated.\n",
    "  - Note the use of `K`,`M`,`B` ... suffix at the end.\n",
    "- Fill Range: The relative start and end range of fields that are populated with data.  Be default: \n",
    "    - sparse tables are all NULLs by having the fill range be 0% to 0% ranges\n",
    "    - dense tables have all fields populated by having the fill range be 0% to 100% of ranges \n",
    "\n",
    "```sql\n",
    "[localhost][arcsrc] 1> \\describe ycsbsparse\n",
    "+-------------+-------------+-----------+-------------+----------------+-------------+\n",
    "| TABLE_SCHEM | COLUMN_NAME | TYPE_NAME | COLUMN_SIZE | DECIMAL_DIGITS | IS_NULLABLE |\n",
    "+-------------+-------------+-----------+-------------+----------------+-------------+\n",
    "| dbo         | YCSB_KEY    | int       |          10 |              0 | NO          |\n",
    "| dbo         | FIELD0      | text      |  2147483647 |         [NULL] | YES         |\n",
    "| dbo         | FIELD1      | text      |  2147483647 |         [NULL] | YES         |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8c315fc-624c-442c-b712-518336f5bfd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd45b349d2e44da9c4d563eb7cadb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Sparse'), BoundedIntText(value=1, description='Table Cnt:', min=1),â€¦"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show YCSB Data Controls\n",
    "VBox([HBox([Label('Sparse'), sparse_cnt, sparse_fieldcount, sparse_fieldlength, sparse_recordcount, sparse_fillpct]),\n",
    "    HBox([Label('Dense'),  dense_cnt, dense_fieldcount, dense_fieldlength, dense_recordcount, dense_fillpct])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8ad9a3e-f752-4e87-b22b-0dbe9487cccb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create SQL Server user, create and load YCSB data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f7f7c0f-9f1d-40e3-a4f8-a02d6a42bf0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replicant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.01.25.1 24.01\n",
      "PATH=/opt/stage/bin/jsqsh-dist-3.0-SNAPSHOT/bin added\n",
      "Msg 15025, Level 16, State 1, Server ron, Line 2\n",
      "The server principal 'arcsrc' already exists.\n",
      "Msg 1801, Level 16, State 3, Server ron, Line 1\n",
      "Database 'arcsrc' already exists. Choose a different database name.\n",
      "Changed database context to 'arcsrc'.\n",
      "Msg 15023, Level 16, State 5, Server ron, Line 1\n",
      "User, group, or role 'arcsrc' already exists in the current database.\n",
      "Starting type=sparse inst=1\n",
      "skip table create\n",
      "skip load need existing count 1000000 -gt 1000000 && field 50 -eq 50 \n",
      "Starting type=dense inst=1\n",
      "skip table create\n",
      "skip load need existing count 100000 -gt 100000 && field 10 -eq 10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "schema dump at /tmp/schema_dump.csv\n",
      "table count at /tmp/list_table_counts.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='. ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \\n    create_user;\\n    y_fieldcount=50 \\n    y_fieldlength=10  \\n    y_recordcount=1M \\n    y_fillstart=0      \\n    y_fillend=0      \\n    load_sparse_data_cnt 1;\\n    y_fieldcount=10 \\n    y_fieldlength=100 \\n    y_recordcount=100K \\n    y_fillstart=0      \\n    y_fillend=10      \\n    load_dense_data_cnt 1;\\n    dump_schema;\\n    list_table_counts', returncode=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run load_sparse_data_cnt and load_dense_data_cnt \n",
    "subprocess.run(f\"\"\". ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \n",
    "    create_user;\n",
    "    y_fieldcount={sparse_fieldcount.value} \n",
    "    y_fieldlength={sparse_fieldlength.value}  \n",
    "    y_recordcount={sparse_recordcount.value} \n",
    "    y_fillstart={math.ceil((sparse_fillpct.value[0] * sparse_fieldcount.value) / 100)}      \n",
    "    y_fillend={int((sparse_fillpct.value[1] * sparse_fieldcount.value) / 100)}      \n",
    "    load_sparse_data_cnt {sparse_cnt.value};\n",
    "    y_fieldcount={dense_fieldcount.value} \n",
    "    y_fieldlength={dense_fieldlength.value} \n",
    "    y_recordcount={dense_recordcount.value} \n",
    "    y_fillstart={math.ceil((dense_fillpct.value[0] * dense_fieldcount.value) / 100)}      \n",
    "    y_fillend={int((dense_fillpct.value[1] * dense_fieldcount.value) / 100)}      \n",
    "    load_dense_data_cnt {dense_cnt.value};\n",
    "    dump_schema;\n",
    "    list_table_counts\"\"\",\n",
    "    shell=True,executable=\"/usr/bin/bash\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bbba479-38b5-46b5-9b46-2a228e1ea005",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table name</th>\n",
       "      <th>min key</th>\n",
       "      <th>max key</th>\n",
       "      <th>field count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YCSBDENSE</td>\n",
       "      <td>0</td>\n",
       "      <td>99999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YCSBSPARSE</td>\n",
       "      <td>0</td>\n",
       "      <td>999999</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   table name  min key  max key  field count\n",
       "0   YCSBDENSE        0    99999           10\n",
       "1  YCSBSPARSE        0   999999           50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show loaded tables\n",
    "pd.read_csv ('/tmp/list_table_counts.csv',header=None, names= ['table name','min key','max key','field count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eba0aa68-95c7-41fd-ba96-431e8a80e6fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Run YCSB and Arcion in the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1aeafcc-3471-47b9-b59d-b14016329940",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Start/Restart YCSB workload at 1 TPS\n",
    "\n",
    "Choose the options in the UI and run the cell below it to start the workload (YCSB).  \n",
    "\n",
    "\n",
    "YCSB update (workload A) controls for Dense and Sparse table groups separated. Each group has a separate control.  However, all of the tables in the group use the same controls.  \n",
    "1. Each table's TPS (throughput per second)\n",
    "   1. 0=fast as possible\n",
    "   2. 1=1 TPS\n",
    "   3. 10=10 TPS\n",
    "2. Each table's threads (concurrency) used to achieve the desired TPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3233053-e7a3-4c56-8544-6d75c718f1dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737285c1051e48caafaf5ab507d96b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Sparse'), BoundedIntText(value=1, description='TPS:', max=1000), Boâ€¦"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show YCSB run controls\n",
    "VBox([HBox([Label('Sparse'), sparse_tps, sparse_threads]), HBox([Label('Dense'),  dense_tps, dense_threads])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33058c18-c9e7-46f2-ab85-618136369430",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replicant\n",
      "24.01.25.1 24.01\n",
      "PATH=/opt/stage/bin/jsqsh-dist-3.0-SNAPSHOT/bin added\n",
      "running ycsb on /tmp/list_table_counts.csv\n",
      "YCSBDENSE,0,99999,10\n",
      "table_name=ycsbdense tabletype=dense record_count=100000 field_count=10 _y_threads=1 _y_target=1 _y_fieldlength=100\n",
      "ycsb ycsbdense pid 2334094\n",
      "ycsb ycsbdense log is at /var/tmp/sqlserver/logs/ycsb.ycsbdense.log\n",
      "ycsb ycsbdense can be killed with . ./demo/sqlserver/run-ycsb-sqlserver-source.sh; kill_ycsb)\n",
      "YCSBSPARSE,0,999999,50\n",
      "table_name=ycsbsparse tabletype=sparse record_count=1000000 field_count=50 _y_threads=1 _y_target=1 _y_fieldlength=10\n",
      "ycsb ycsbsparse pid 2334103\n",
      "ycsb ycsbsparse log is at /var/tmp/sqlserver/logs/ycsb.ycsbsparse.log\n",
      "ycsb ycsbsparse can be killed with . ./demo/sqlserver/run-ycsb-sqlserver-source.sh; kill_ycsb)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='. ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \\n    kill_ycsb;\\n    y_target_sparse=1 \\n    y_target_dense=1 \\n    y_threads_sparse=1 \\n    y_threads_dense=1 \\n    y_fieldlength_sparse=10 \\n    y_fieldlength_dense=100 \\n    start_ycsb;', returncode=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start/restart YCSB run\n",
    "subprocess.run(f\"\"\". ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \n",
    "    kill_ycsb;\n",
    "    y_target_sparse={sparse_tps.value} \n",
    "    y_target_dense={dense_tps.value} \n",
    "    y_threads_sparse={sparse_threads.value} \n",
    "    y_threads_dense={dense_threads.value} \n",
    "    y_fieldlength_sparse={sparse_fieldlength.value} \n",
    "    y_fieldlength_dense={dense_fieldlength.value} \n",
    "    start_ycsb;\"\"\",\n",
    "    shell=True,executable=\"/usr/bin/bash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb6734eb-5342-48b5-868b-750218370b54",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Start Arcion\n",
    "\n",
    "Choose the options in the UI and run the cell below it to start the replication.  \n",
    "\n",
    "The following control are avail in the demo.  \n",
    "- Arcion - replication type and CDC methods  \n",
    "- Threads - control the parallelism.\n",
    "- Target - null, unity catalog or delta lake\n",
    "\n",
    "NOTE: Full mode does not work at this time.\n",
    "\n",
    "For SQL Server, change tracking, cdc are available for demo.  \n",
    "\n",
    "Performance is mainly controlled by the thread count by the extract and apply process.\n",
    "Additional controls are customizable via modifying the YAML files directly below.\n",
    "- [CDC YAML files](./demo/sqlserver/yaml/cdc/)\n",
    "- [Change Tracking YAML files](./demo/sqlserver/yaml/change/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d603b1d4-bb2c-418b-acfe-894441efe01e",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa0f929c4f14e66b4cebd4c82ddf04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Arcion'), Dropdown(description='Replication:', options=('snapshot',â€¦"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show Arcion and DBX controls\n",
    "\n",
    "# cluster where the notebook is running to auto populate the destinations\n",
    "spark_url=\"\"\n",
    "databricks_url=\"\"\n",
    "workspaceUrl=\"\"\n",
    "username=\"\"\n",
    "try:\n",
    "    cluster_id = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterId\")\n",
    "    workspace_id =spark.conf.get(\"spark.databricks.clusterUsageTags.clusterOwnerOrgId\")\n",
    "\n",
    "    # clusterName = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterName\")\n",
    "\n",
    "    workspaceUrl = spark.conf.get(\"spark.databricks.workspaceUrl\") # host name\n",
    "\n",
    "    http_path = f\"sql/protocolv1/o/{workspace_id}/{cluster_id}\"\n",
    "\n",
    "    spark_url=f\"jdbc:spark://{workspaceUrl}:443/default;transportMode=http;ssl=1;httpPath={http_path};AuthMech=3;UID=token;\"\n",
    "    databricks_url=f\"jdbc:databricks://{workspaceUrl}:443/default;transportMode=http;ssl=1;httpPath={http_path};AuthMech=3;UID=token;\"\n",
    "    username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "\n",
    "except:\n",
    "    pass\n",
    "dbx_spark_url.value = spark_url\n",
    "dbx_databricks_url.value = databricks_url\n",
    "dbx_hostname.value = workspaceUrl\n",
    "dbx_username.value = username\n",
    "\n",
    "VBox([\n",
    "      HBox([Label('Arcion'), repl_mode, cdc_mode]),\n",
    "      HBox([Label('Threads'), snapshot_threads, realtime_threads, delta_threads]),\n",
    "      HBox([Label('Target'), dbx_destinations, dbx_staging]),\n",
    "      HBox([Label('Workspace'), dbx_spark_url, dbx_databricks_url, dbx_hostname, dbx_username]),\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75a0ede1-4383-4f3e-b9c8-5e601c35bfcb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change real-time\n",
      "replicant\n",
      "24.01.25.1 24.01\n",
      "PATH=/opt/stage/bin/jsqsh-dist-3.0-SNAPSHOT/bin added\n",
      "/home/rslee/github/dbx/ingestion/demo/sqlserver\n",
      "enable change tracking on database arcsrc\n",
      "skip ALTER DATABASE arcsrc SET CHANGE_TRACKING = ON  (CHANGE_RETENTION = 2 DAYS, AUTO_CLEANUP = ON);\n",
      "skip ALTER TABLE replicate_io_audit_ddl ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE replicate_io_audit_tbl_cons ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE replicate_io_audit_tbl_schema ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE YCSBDENSE ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE YCSBSPARSE ENABLE CHANGE_TRACKING;\n",
      "replicant\n",
      "arcion pid 2348621\n",
      "arcion console is at /var/tmp/sqlserver/logs/3fa6ad8e1/arcion.log\n",
      "arcion log is at /var/tmp/sqlserver/logs/3fa6ad8e1\n",
      "arcion can be killed with . ./demo/sqlserver/run-ycsb-sqlserver-source.sh; kill_arcion)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd /var/tmp/sqlserver/logs/3fa6ad8e1\n",
      "+ set +x\n",
      "+ JAVA_HOME=\n",
      "+ /opt/stage/arcion/24.01.25.1/bin/replicant real-time /var/tmp/sqlserver/logs/3fa6ad8e1/src.yaml /var/tmp/sqlserver/logs/3fa6ad8e1/dst.yaml --applier /var/tmp/sqlserver/logs/3fa6ad8e1/applier.yaml --general /var/tmp/sqlserver/logs/3fa6ad8e1/general.yaml --extractor /var/tmp/sqlserver/logs/3fa6ad8e1/extractor.yaml --filter /var/tmp/sqlserver/logs/3fa6ad8e1/filter.yaml --map /var/tmp/sqlserver/logs/3fa6ad8e1/map.yaml --overwrite --id 3fa6ad8e1 --merge\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=\". ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \\n    echo $PROG_DIR;\\n    cd $PROG_DIR;\\n    kill_arcion;\\n    a_repltype='real-time'\\n    SRCDB_SNAPSHOT_THREADS='1' \\n    SRCDB_REALTIME_THREADS='1' \\n    SRCDB_DELTA='1'\\n    DSTDB_TYPE='deltalake'\\n    DSTDB_STAGE='dbfs'\\n    DBX_SPARK_URL=''\\n    DBX_DATABRICKS_URL=''\\n    DBX_ACCESS_TOKEN=''\\n    DBX_HOSTNAME=''\\n    DBX_DBFS_ROOT='/'\\n    DBX_USERNAME=''\\n    start_change_arcion;\", returncode=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start/restart Arcion\n",
    "print (f\"\"\"{cdc_mode.value} {repl_mode.value}\"\"\")\n",
    "subprocess.run(f\"\"\". ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \n",
    "    echo $PROG_DIR;\n",
    "    cd $PROG_DIR;\n",
    "    kill_arcion;\n",
    "    a_repltype='{repl_mode.value}'\n",
    "    SRCDB_SNAPSHOT_THREADS='{snapshot_threads.value}' \n",
    "    SRCDB_REALTIME_THREADS='{realtime_threads.value}' \n",
    "    SRCDB_DELTA='{delta_threads.value}'\n",
    "    DSTDB_TYPE='{dbx_destinations.value}'\n",
    "    DSTDB_STAGE='{dbx_staging.value}'\n",
    "    DBX_SPARK_URL='{dbx_spark_url.value}'\n",
    "    DBX_DATABRICKS_URL='{dbx_databricks_url.value}'\n",
    "    DBX_ACCESS_TOKEN='{dbx_access_token.value}'\n",
    "    DBX_HOSTNAME='{dbx_hostname.value}'\n",
    "    DBX_DBFS_ROOT='/{dbx_username.value}'\n",
    "    DBX_USERNAME='{dbx_username.value}'\n",
    "    start_{cdc_mode.value}_arcion;\"\"\",\n",
    "    shell=True,executable=\"/usr/bin/bash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80bc69d4-63ec-4bdd-af90-bfe43fd5bb11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Untitled-1",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
