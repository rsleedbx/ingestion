{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15a3e62d-a594-4d8e-b979-55f5d7162955",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Purpose of Demo and Performance Demo\n",
    "This demo environment is designed to help answer the following questions:\n",
    "- How does it work\n",
    "- How fast is snapshot (bulk insert) performance\n",
    "- How fast is realtime (CDC) performance\n",
    "- What are the RAS characteristics\n",
    "\n",
    "Demo is not for for:\n",
    "- Schema and data type validation\n",
    "- Tuning based on environmental factors\n",
    "- Data value conversion\n",
    "- HA and resilience testing \n",
    "  \n",
    "## Demo Environment\n",
    "\n",
    "### Infrastructures\n",
    "\n",
    "The following the demo environment.\n",
    "```text\n",
    "  +--------------Databricks Personal Compute Cluster--------------------------+  \n",
    "  |  +-----------+    +-----------+          +----------+     +------------+  |\n",
    "  |  |  Workload |    | Source DB |          |  Arcion  |     | Target DB  |  | \n",
    "  |  |           |    |           | <--------|          |     |            |  |\n",
    "  |  |   YCSB    | -->| SQL Server|          | Notebook | --> | Databricks |  |\n",
    "  |  |           |    |           | -------->|   CLI    |     |            |  |\n",
    "  |  +-----------+    +-----------+          +----------+     +------------+  |\n",
    "  +---------------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "In the production, the following is expected separation.\n",
    "```text\n",
    "  +----------Customer Cloud---------+   F   +---- Databricks Serverless ------+  \n",
    "  |  +-----------+    +-----------+ |   I   | +----------+     +------------+ |\n",
    "  |  |  Workload |    | Source DB | |   R   | |  Arcion  |     | Target DB  | | \n",
    "  |  |           |    |           | | <-E-- | |          |     |            | |\n",
    "  |  |   YCSB    | -->| SQL Server| |   W   | | Notebook | --> | Databricks | |\n",
    "  |  |           |    |           | | --A-> | |    UI    |     |            | |\n",
    "  |  +-----------+    +-----------+ |   L   | +----------+     +------------+ |  \n",
    "  +---------------------------------+   L   +---------------------------------+\n",
    "```\n",
    "\n",
    "### Schema \n",
    "\n",
    "In the demo, there are dense and sparse tables.\n",
    "Dense and sparse tables try to model a star schema.\n",
    "Dense tables can be long and wide and have most of the fields populated.\n",
    "Sparse tables can be short and wide if required and have most of the fields NOT populated.\n",
    "\n",
    "- An arbitrary number of dense and sparse tables be defined.  \n",
    "- Each table can have defined number of fields.  \n",
    "- Range of populated fields can be defined.\n",
    "- A specified number of records are inserted/appended using native bulk copy.  \n",
    "\n",
    "Dense tables have all fields populated to data to the max length of the field.\n",
    "Sparse tables fields are populated with NULLs.\n",
    "\n",
    "```text\n",
    "+--------+    +--------+  +--------+    +--------+\n",
    "| Dense  |    | Dense  |  | Sparse |    | Sparse | \n",
    "| Tables | ...| Tables |  | Tables | ...| Tables |\n",
    "|   1    |    |   n    |  |   1    |    |    n   |\n",
    "+--------+    +--------+  +--------+    +--------+\n",
    "```\n",
    "\n",
    "Dense and sparse tables allow one to model capacity and performance of:\n",
    "- Star schema\n",
    "- IOT data \n",
    "- big data\n",
    "\n",
    "### Workload\n",
    "\n",
    "Workload uses (customized)[https://github.com/arcionlabs/YCSB/tree/jdbc_url_delim] Yahoo Cloud Services Benchmark (YCSB)[https://github.com/brianfrankcooper/YCSB].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fd45e92-ead4-45c5-be8f-6a0bb78534f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Install Arcion, YCSB and SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9cca325-b2f8-4be4-aaf6-862be36fe237",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# prep python env\n",
    "import subprocess\n",
    "import math\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox, Label\n",
    "\n",
    "# setup GUI elements\n",
    "\n",
    "repl_mode = widgets.Dropdown(options=['snapshot', 'real-time', 'full'],value='snapshot',\n",
    "    description='Replication:',\n",
    ")\n",
    "cdc_mode = widgets.Dropdown(options=['change', 'cdc'],value='change',\n",
    "    description='CDC Method:',\n",
    ")\n",
    "\n",
    "snapshot_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Snapshot Threads:',\n",
    ")\n",
    "\n",
    "realtime_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Real Time Threads:',\n",
    ")    \n",
    "\n",
    "delta_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Delta Snapshot Threads:',\n",
    ")    \n",
    "\n",
    "dbx_destinations = widgets.Dropdown(options=['null', 'deltalake', 'unitycatalog'],value='null',\n",
    "    description='Destinations:',\n",
    ")\n",
    "dbx_staging = widgets.Dropdown(options=['dbfs'],value='dbfs',\n",
    "    description='Staging:',\n",
    ")\n",
    "\n",
    "sparse_cnt = widgets.BoundedIntText(value=1,min=1,max=100,\n",
    "    description='Table Cnt:',\n",
    ")\n",
    "sparse_fieldcount = widgets.BoundedIntText(value=50,min=0,max=9000,\n",
    "    description='# of Fields:',\n",
    ")\n",
    "sparse_fieldlength = widgets.BoundedIntText(value=10,min=1,max=1000,\n",
    "    description='Field Len:',\n",
    ")\n",
    "\n",
    "sparse_tps = widgets.BoundedIntText(value=1,min=0,max=1000,\n",
    "    description='TPS:',\n",
    ")\n",
    "sparse_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Threads:',\n",
    ")\n",
    "sparse_recordcount = widgets.Text(value=\"1M\",\n",
    "    description='Rec Cnt:',\n",
    ")\n",
    "\n",
    "sparse_fillpct = widgets.IntRangeSlider(value=[0,0],min=0,max=100,step=1,\n",
    "    description='Fill Range:', orientation='horizontal', readout=False\n",
    ")\n",
    "\n",
    "dense_cnt = widgets.BoundedIntText(value=1,min=1,max=100,\n",
    "    description='Table Cnt:',\n",
    ")\n",
    "dense_fieldcount = widgets.BoundedIntText(value=10,min=0,max=9000,\n",
    "    description='# of Fields:',\n",
    ")\n",
    "dense_fieldlength = widgets.BoundedIntText(value=100,min=1,max=1000,\n",
    "    description='Field Len:',\n",
    ")\n",
    "dense_recordcount = widgets.Text(value=\"100K\",\n",
    "    description='Rec Cnt:',\n",
    ")\n",
    "\n",
    "dense_tps = widgets.BoundedIntText(value=1,min=0,max=1000,\n",
    "    description='TPS:',\n",
    ")\n",
    "dense_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Threads:',\n",
    ")\n",
    "\n",
    "dense_fillpct = widgets.IntRangeSlider(value=[0,100],min=0,max=100,step=1,\n",
    "    description='Fill Range:', orientation='horizontal', readout=False\n",
    ")\n",
    "\n",
    "dbx_spark_url = widgets.Textarea(value='',\n",
    "    description='Spark URL:',\n",
    ")\n",
    "\n",
    "dbx_databricks_url = widgets.Textarea(value='',\n",
    "    description='Databricks URL:',\n",
    ")\n",
    "\n",
    "dbx_hostname = widgets.Textarea(value='',\n",
    "    description='Hostname:',\n",
    ")\n",
    "\n",
    "arcion_license = widgets.Textarea(value='',\n",
    "    description='Arcion Lic',\n",
    ")\n",
    "\n",
    "dbx_access_token = widgets.Textarea(value='',\n",
    "    description='Access Token',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8959eebfd14b019d8146f50b3bab40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='License'), Textarea(value='', description='Arcion Lic'), Textarea(vâ€¦"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VBox([HBox([Label('License'), arcion_license, dbx_access_token]), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a208371c-d54e-4158-81be-16483107efa0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deltalake /opt/stage/libs/SparkJDBC42.jar found\n",
      "lakehouse  /opt/stage/libs/DatabricksJDBC42.jar found\n",
      "postgres  /opt/stage/libs/postgresql-42.7.1.jar found\n",
      "mariadb  /opt/stage/libs/mariadb-java-client-3.3.2.jar found\n",
      "oracle /opt/stage/libs/ojdbc8.jar found\n",
      "log4j /opt/stage/libs/log4j-1.2.17.jar found\n",
      "arcion  /opt/stage/arcion/replicant-cli/bin/replicant found\n",
      "checking jar(s) in /opt/stage/arcion/24.01.25.1/replicant-cli/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/24.01.25.1/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/replicant-cli/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/replicate-cli-23.05.31.29/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/23.05.31.31/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/24.01.25.7/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/23.09.29.11/lib for updates\n",
      "Arcion license found\n",
      "YCSB  /opt/stage/ycsb/ycsb-jdbc-binding-0.18.0-SNAPSHOT  found\n",
      "numfmt found\n",
      "checking jar(s) in /opt/stage/ycsb/ycsb-jdbc-binding-0.18.0-SNAPSHOT/lib for updates\n",
      "apt-utils already installed\n",
      "mssql-server already installed\n",
      "mssql-tools18 already installed\n",
      "unixodbc-dev alrady installed\n",
      "sqlserver already started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='bin/install-sqlserver.sh', returncode=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(f\"\"\"bin/download-jars.sh\"\"\",shell=True,executable=\"/usr/bin/bash\")\n",
    "subprocess.run(f\"\"\"ARCION_LICENSE={arcion_license.value} bin/install-arcion.sh\"\"\",shell=True,executable=\"/usr/bin/bash\")\n",
    "subprocess.run(f\"\"\"bin/install-ycsb.sh\"\"\",shell=True,executable=\"/usr/bin/bash\")\n",
    "subprocess.run(f\"\"\"bin/install-sqlserver.sh\"\"\",shell=True,executable=\"/usr/bin/bash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "427dc8c9-96f3-4ac6-bf41-4efd371f3b04",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Customize schema and size\n",
    "\n",
    "Existing tables will be appended with additional rows if the `Fill Range` is the same.  \n",
    "Increase the `Table Count` to create additional tables.  \n",
    "\n",
    "The following options are available:\n",
    "- Table count (Table Cnt): The number of tables to create.  \n",
    "  - Table names are `ycsbdense`, `ycsbdense2`, `ycsbdense3`, ... and `ycssparse`, `ycsbdense2`, and `ycsbdense3` ...\n",
    "- Number of Fields (# of Fields): The number of fields per table.  \n",
    "  - The field names are `FIELD0`, `FIELD1`, `FIELD2`, ...\n",
    "  - Note the use of `K`,`M`,`B` ... suffix at the end.\n",
    "- Field Length (Field Len): The length of random character data populated per field.  \n",
    "  - Note the use of `K`,`M`,`B` ... suffix at the end.\n",
    "- Record Count (Rec Cnt): The number of records per table generated.\n",
    "  - Note the use of `K`,`M`,`B` ... suffix at the end.\n",
    "- Fill Range: The relative start and end range of fields that are populated with data.  Be default: \n",
    "    - sparse tables are all NULLs by having the fill range be 0% to 0% ranges\n",
    "    - dense tables have all fields populated by having the fill range be 0% to 100% of ranges \n",
    "\n",
    "```sql\n",
    "[localhost][arcsrc] 1> \\describe ycsbsparse\n",
    "+-------------+-------------+-----------+-------------+----------------+-------------+\n",
    "| TABLE_SCHEM | COLUMN_NAME | TYPE_NAME | COLUMN_SIZE | DECIMAL_DIGITS | IS_NULLABLE |\n",
    "+-------------+-------------+-----------+-------------+----------------+-------------+\n",
    "| dbo         | YCSB_KEY    | int       |          10 |              0 | NO          |\n",
    "| dbo         | FIELD0      | text      |  2147483647 |         [NULL] | YES         |\n",
    "| dbo         | FIELD1      | text      |  2147483647 |         [NULL] | YES         |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8c315fc-624c-442c-b712-518336f5bfd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# show YCSB Data Controls\n",
    "VBox([HBox([Label('Sparse'), sparse_cnt, sparse_fieldcount, sparse_fieldlength, sparse_recordcount, sparse_fillpct]),\n",
    "    HBox([Label('Dense'),  dense_cnt, dense_fieldcount, dense_fieldlength, dense_recordcount, dense_fillpct])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8ad9a3e-f752-4e87-b22b-0dbe9487cccb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create SQL Server user, create and load YCSB data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f7f7c0f-9f1d-40e3-a4f8-a02d6a42bf0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# run load_sparse_data_cnt and load_dense_data_cnt \n",
    "subprocess.run(f\"\"\". ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \n",
    "    create_user;\n",
    "    y_fieldcount={sparse_fieldcount.value} \n",
    "    y_fieldlength={sparse_fieldlength.value}  \n",
    "    y_recordcount={sparse_recordcount.value} \n",
    "    y_fillstart={math.ceil((sparse_fillpct.value[0] * sparse_fieldcount.value) / 100)}      \n",
    "    y_fillend={int((sparse_fillpct.value[1] * sparse_fieldcount.value) / 100)}      \n",
    "    load_sparse_data_cnt {sparse_cnt.value};\n",
    "    y_fieldcount={dense_fieldcount.value} \n",
    "    y_fieldlength={dense_fieldlength.value} \n",
    "    y_recordcount={dense_recordcount.value} \n",
    "    y_fillstart={math.ceil((dense_fillpct.value[0] * dense_fieldcount.value) / 100)}      \n",
    "    y_fillend={int((dense_fillpct.value[1] * dense_fieldcount.value) / 100)}      \n",
    "    load_dense_data_cnt {dense_cnt.value};\n",
    "    dump_schema;\n",
    "    list_table_counts\"\"\",\n",
    "    shell=True,executable=\"/usr/bin/bash\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bbba479-38b5-46b5-9b46-2a228e1ea005",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table name</th>\n",
       "      <th>min key</th>\n",
       "      <th>max key</th>\n",
       "      <th>field count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YCSBDENSE</td>\n",
       "      <td>1</td>\n",
       "      <td>99999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YCSBSPARSE</td>\n",
       "      <td>1</td>\n",
       "      <td>1009999</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   table name  min key  max key  field count\n",
       "0   YCSBDENSE        1    99999           10\n",
       "1  YCSBSPARSE        1  1009999           20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show loaded tables\n",
    "pd.read_csv ('/tmp/list_table_counts.csv',header=None, names= ['table name','min key','max key','field count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eba0aa68-95c7-41fd-ba96-431e8a80e6fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Run YCSB and Arcion in the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1aeafcc-3471-47b9-b59d-b14016329940",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Start/Restart YCSB workload at 1 TPS\n",
    "\n",
    "Choose the options in the UI and run the cell below it to start the workload (YCSB).  \n",
    "\n",
    "\n",
    "YCSB update (workload A) controls for Dense and Sparse table groups separated. Each group has a separate control.  However, all of the tables in the group use the same controls.  \n",
    "1. Each table's TPS (throughput per second)\n",
    "   1. 0=fast as possible\n",
    "   2. 1=1 TPS\n",
    "   3. 10=10 TPS\n",
    "2. Each table's threads (concurrency) used to achieve the desired TPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3233053-e7a3-4c56-8544-6d75c718f1dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# show YCSB run controls\n",
    "VBox([HBox([Label('Sparse'), sparse_tps, sparse_threads]), HBox([Label('Dense'),  dense_tps, dense_threads])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33058c18-c9e7-46f2-ab85-618136369430",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replicant\n",
      " .\n",
      "PATH=/opt/stage/bin/jsqsh-dist-3.0-SNAPSHOT/bin added\n",
      "running ycsb on /tmp/list_table_counts.csv\n",
      "YCSBDENSE,1,99999,10\n",
      "table_name=ycsbdense tabletype=dense record_count=100000 field_count=10 _y_threads=1 _y_target=1 _y_fieldlength=100\n",
      "ycsb ycsbdense pid 1811069\n",
      "ycsb ycsbdense log is at /var/tmp/sqlserver/logs/ycsb.ycsbdense.log\n",
      "ycsb ycsbdense can be killed with . ./demo/sqlserver/run-ycsb-sqlserver-source.sh; kill_ycsb)\n",
      "YCSBSPARSE,1,1009999,20\n",
      "table_name=ycsbsparse tabletype=sparse record_count=1010000 field_count=20 _y_threads=1 _y_target=1 _y_fieldlength=10\n",
      "ycsb ycsbsparse pid 1811077\n",
      "ycsb ycsbsparse log is at /var/tmp/sqlserver/logs/ycsb.ycsbsparse.log\n",
      "ycsb ycsbsparse can be killed with . ./demo/sqlserver/run-ycsb-sqlserver-source.sh; kill_ycsb)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='. ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \\n    kill_ycsb;\\n    y_target_sparse=1 \\n    y_target_dense=1 \\n    y_threads_sparse=1 \\n    y_threads_dense=1 \\n    y_fieldlength_sparse=10 \\n    y_fieldlength_dense=100 \\n    start_ycsb;', returncode=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start/restart YCSB run\n",
    "subprocess.run(f\"\"\". ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \n",
    "    kill_ycsb;\n",
    "    y_target_sparse={sparse_tps.value} \n",
    "    y_target_dense={dense_tps.value} \n",
    "    y_threads_sparse={sparse_threads.value} \n",
    "    y_threads_dense={dense_threads.value} \n",
    "    y_fieldlength_sparse={sparse_fieldlength.value} \n",
    "    y_fieldlength_dense={dense_fieldlength.value} \n",
    "    start_ycsb;\"\"\",\n",
    "    shell=True,executable=\"/usr/bin/bash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb6734eb-5342-48b5-868b-750218370b54",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Start Arcion\n",
    "\n",
    "Choose the options in the UI and run the cell below it to start the replication.  \n",
    "\n",
    "The following control are avail in the demo.  \n",
    "- Arcion - replication type and CDC methods  \n",
    "- Threads - control the parallelism.\n",
    "- Target - null, unity catalog or delta lake\n",
    "\n",
    "NOTE: Full mode does not work at this time.\n",
    "\n",
    "For SQL Server, change tracking, cdc are available for demo.  \n",
    "\n",
    "Performance is mainly controlled by the thread count by the extract and apply process.\n",
    "Additional controls are customizable via modifying the YAML files directly below.\n",
    "- [CDC YAML files](./demo/sqlserver/yaml/cdc/)\n",
    "- [Change Tracking YAML files](./demo/sqlserver/yaml/change/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d603b1d4-bb2c-418b-acfe-894441efe01e",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da890df118514959a1bd01cbd42a545a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Arcion'), Dropdown(description='Replication:', options=('snapshot',â€¦"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show Arcion controls\n",
    "\n",
    "# cluster where the notebook is running to auto populate the destinations\n",
    "spark_url=\"\"\n",
    "databricks_url=\"\"\n",
    "workspaceUrl=\"\"\n",
    "try:\n",
    "    cluster_id = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterId\")\n",
    "    workspace_id =spark.conf.get(\"spark.databricks.clusterUsageTags.clusterOwnerOrgId\")\n",
    "\n",
    "    # clusterName = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterName\")\n",
    "\n",
    "    workspaceUrl = spark.conf.get(\"spark.databricks.workspaceUrl\") # host name\n",
    "\n",
    "    http_path = f\"sql/protocolv1/o/{workspace_id}/{cluster_id}\"\n",
    "\n",
    "    spark_url=f\"jdbc:spark://{workspaceUrl}:443/default;transportMode=http;ssl=1;httpPath={http_path};AuthMech=3\"\n",
    "    databricks_url=f\"jdbc:databricks://{workspaceUrl}:443/default;transportMode=http;ssl=1;httpPath={http_path};AuthMech=3\"\n",
    "except:\n",
    "    pass\n",
    "dbx_spark_url.value = spark_url\n",
    "dbx_databricks_url.value = databricks_url\n",
    "dbx_hostname.value = workspaceUrl\n",
    "\n",
    "VBox([\n",
    "      HBox([Label('Arcion'), repl_mode, cdc_mode]),\n",
    "      HBox([Label('Threads'), snapshot_threads, realtime_threads, delta_threads]),\n",
    "      HBox([Label('Target'), dbx_destinations, dbx_staging]),\n",
    "      HBox([Label('DBX URL'), dbx_spark_url, dbx_databricks_url, dbx_hostname]),\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75a0ede1-4383-4f3e-b9c8-5e601c35bfcb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change snapshot\n",
      "replicant\n",
      " .\n",
      "PATH=/opt/stage/bin/jsqsh-dist-3.0-SNAPSHOT/bin added\n",
      "/home/rslee/github/dbx/ingestion/demo/sqlserver\n",
      "enable change tracking on database arcsrc\n",
      "skip ALTER DATABASE arcsrc SET CHANGE_TRACKING = ON  (CHANGE_RETENTION = 2 DAYS, AUTO_CLEANUP = ON);\n",
      "skip ALTER TABLE replicate_io_audit_ddl ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE replicate_io_audit_tbl_cons ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE replicate_io_audit_tbl_schema ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE YCSBDENSE ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE YCSBSPARSE ENABLE CHANGE_TRACKING;\n",
      "replicant\n",
      "arcion pid 1845697\n",
      "arcion console is at /var/tmp/sqlserver/logs/3fa605507/arcion.log\n",
      "arcion log is at /var/tmp/sqlserver/logs/3fa605507\n",
      "arcion can be killed with . ./demo/sqlserver/run-ycsb-sqlserver-source.sh; kill_arcion)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='. ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \\n    echo $PROG_DIR;\\n    cd $PROG_DIR;\\n    kill_arcion;\\n    a_repltype=snapshot \\n    SRCDB_SNAPSHOT_THREADS=1 \\n    SRCDB_REALTIME_THREADS=1 \\n    SRCDB_DELTA=1_THREADS\\n    DSTDB_TYPE=unitycatalog\\n    DSTDB_STAGE=dbfs\\n    DBX_SPARK_URL=jdbc:spark://adb-984752964297111.11.azuredatabricks.net:443/default;transportMode=http;ssl=1;httpPath=sql/protocolv1/o/984752964297111/0221-153440-9aliiyt;AuthMech=3\\n    DBX_DATABRICKS_URL=jdbc:databricks://adb-984752964297111.11.azuredatabricks.net:443/default;transportMode=http;ssl=1;httpPath=sql/protocolv1/o/984752964297111/0221-153440-9aliiyt;AuthMech=3\\n    DBX_ACCESS_TOKEN=dapifcc46a6f4c28114f313699ce7da10c43\\n    DBX_HOSTNAME=$\\n    start_change_arcion;', returncode=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start/restart Arcion\n",
    "print (f\"\"\"{cdc_mode.value} {repl_mode.value}\"\"\")\n",
    "subprocess.run(f\"\"\". ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \n",
    "    echo $PROG_DIR;\n",
    "    cd $PROG_DIR;\n",
    "    kill_arcion;\n",
    "    a_repltype={repl_mode.value} \n",
    "    SRCDB_SNAPSHOT_THREADS={snapshot_threads.value} \n",
    "    SRCDB_REALTIME_THREADS={realtime_threads.value} \n",
    "    SRCDB_DELTA={delta_threads.value}_THREADS\n",
    "    DSTDB_TYPE={dbx_destinations.value}\n",
    "    DSTDB_STAGE={dbx_staging.value}\n",
    "    DBX_SPARK_URL={dbx_spark_url.value}\n",
    "    DBX_DATABRICKS_URL={dbx_databricks_url.value}\n",
    "    DBX_ACCESS_TOKEN={dbx_access_token.value}\n",
    "    DBX_HOSTNAME={dbx_hostname.value}\n",
    "    start_{cdc_mode.value}_arcion;\"\"\",\n",
    "    shell=True,executable=\"/usr/bin/bash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80bc69d4-63ec-4bdd-af90-bfe43fd5bb11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Untitled-1",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
