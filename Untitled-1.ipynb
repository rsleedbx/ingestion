{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose of Demo and Performance Demo\n",
    "This demo environment is designed to help answer the following questions:\n",
    "- How does it work\n",
    "- How fast is snapshot (bulk insert) performance\n",
    "- How fast is realtime (CDC) performance\n",
    "- What are the RAS characteristics\n",
    "\n",
    "Demo is not for for:\n",
    "- Schema and data type validation\n",
    "- Tuning based on environmental factors\n",
    "- Data value conversion\n",
    "- HA and resilience testing \n",
    "  \n",
    "## Demo Environment\n",
    "\n",
    "### Infrastructures\n",
    "\n",
    "The following the demo environment.\n",
    "```text\n",
    "  +--------Databricks Personal Compute Cluster--------------------------+  \n",
    "  |  +-----------+    +-----------+    +----------+     +------------+  |\n",
    "  |  |  Workload |    | Source DB |    |  Arcion  |     | Target DB  |  | \n",
    "  |  |           |    |           | <--|          |     |            |  |\n",
    "  |  |   YCSB    | -->| SQL Server|    | Notebook | --> | Databricks |  |\n",
    "  |  |           |    |           | -->|   CLI    |     |            |  |\n",
    "  |  +-----------+    +-----------+    +----------+     +------------+  |\n",
    "  +---------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "In the production, the following is expected separation.\n",
    "```text\n",
    "  +----------Customer Cloud---------+   F   +---- Databricks Serverless ------+  \n",
    "  |  +-----------+    +-----------+ |   I   | +----------+     +------------+ |\n",
    "  |  |  Workload |    | Source DB | |   R   | |  Arcion  |     | Target DB  | | \n",
    "  |  |           |    |           | | <-E-- | |          |     |            | |\n",
    "  |  |   YCSB    | -->| SQL Server| |   W   | | Notebook |  -->| Databricks | |\n",
    "  |  |           |    |           | | --A-> | |    UI    |     |            | |\n",
    "  |  +-----------+    +-----------+ |   L   | +----------+     +------------+ |  \n",
    "  +---------------------------------+   L   +---------------------------------+\n",
    "```\n",
    "\n",
    "### Schema \n",
    "\n",
    "In the demo, there are dense and sparse tables.\n",
    "Dense and sparse tables try to model a star schema.\n",
    "Dense tables can be long and wide and have most of the fields populated.\n",
    "Sparse tables can be short and wide if required and have most of the fields NOT populated.\n",
    "\n",
    "- An arbitrary number of dense and sparse tables be defined.  \n",
    "- Each table can have defined number of fields.  \n",
    "- Range of populated fields can be defined.\n",
    "- A specified number of records are inserted/appended using native bulk copy.  \n",
    "\n",
    "Dense tables have all fields populated to data to the max length of the field.\n",
    "Sparse tables fields are populated with NULLs.\n",
    "\n",
    "```text\n",
    "+--------+    +--------+  +--------+    +--------+\n",
    "| Dense  |    | Dense  |  | Sparse |    | Sparse | \n",
    "| Tables | ...| Tables |  | Tables | ...| Tables |\n",
    "|   1    |    |   n    |  |   1    |    |    n   |\n",
    "+--------+    +--------+  +--------+    +--------+\n",
    "```\n",
    "\n",
    "Dense and sparse tables allow one to model capacity and performance of:\n",
    "- Star schema\n",
    "- IOT data \n",
    "- big data\n",
    "\n",
    "### Workload\n",
    "\n",
    "Workload uses (customized)[https://github.com/arcionlabs/YCSB/tree/jdbc_url_delim] Yahoo Cloud Services Benchmark (YCSB)[https://github.com/brianfrankcooper/YCSB].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Arcion, YCSB and SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets in /home/rslee/.local/lib/python3.10/site-packages (8.1.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /home/rslee/.local/lib/python3.10/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /home/rslee/.local/lib/python3.10/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/rslee/.local/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/rslee/.local/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/rslee/.local/lib/python3.10/site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/rslee/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/rslee/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: stack-data in /home/rslee/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/rslee/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/rslee/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/rslee/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/rslee/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in /home/rslee/.local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/rslee/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/rslee/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/rslee/.local/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# prep python env\n",
    "%pip install ipywidgets\n",
    "import subprocess\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deltalake /opt/stage/libs/SparkJDBC42.jar found\n",
      "lakehouse  /opt/stage/libs/DatabricksJDBC42.jar found\n",
      "postgres  /opt/stage/libs/postgresql-42.7.1.jar found\n",
      "mariadb  /opt/stage/libs/mariadb-java-client-3.3.2.jar found\n",
      "oracle /opt/stage/libs/ojdbc8.jar found\n",
      "log4j /opt/stage/libs/log4j-1.2.17.jar found\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arcion  /opt/stage/arcion/replicant-cli/bin/replicant found\n",
      "checking jar(s) in /opt/stage/arcion/24.01.25.1/replicant-cli/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/24.01.25.1/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/replicant-cli/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/replicate-cli-23.05.31.29/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/23.05.31.31/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/24.01.25.7/lib for updates\n",
      "checking jar(s) in /opt/stage/arcion/23.09.29.11/lib for updates\n",
      "\n",
      "YCSB  /opt/stage/ycsb/ycsb-jdbc-binding-0.18.0-SNAPSHOT  found\n",
      "numfmt found\n",
      "checking jar(s) in /opt/stage/ycsb/ycsb-jdbc-binding-0.18.0-SNAPSHOT/lib for updates\n",
      "\n",
      "sqlserver found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# install YCSB, Arcion, Database, JAR files\n",
    "print (subprocess.run(\"bin/download-jars.sh\",stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
    "print (subprocess.run(\"bin/install-arcion.sh\",stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
    "print (subprocess.run(\"bin/install-ycsb.sh\",stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
    "print (subprocess.run(\"bin/install-sqlserver.sh\",stdout=subprocess.PIPE).stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup GUI elements\n",
    "from libpython.arcion_control import *    \n",
    "from libpython.ycsb_control import *    \n",
    "#show_arcion_config()\n",
    "#show_ycsb_config()\n",
    "\n",
    "repl_mode = widgets.Dropdown(options=['snapshot', 'real-time', 'full'],value='snapshot',\n",
    "    description='Replication:',\n",
    ")\n",
    "cdc_mode = widgets.Dropdown(options=['change', 'cdc'],value='change',\n",
    "    description='CDC Method:',\n",
    ")\n",
    "\n",
    "snapshot_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Snapshot Threads:',\n",
    ")\n",
    "\n",
    "realtime_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Real Time Threads:',\n",
    ")    \n",
    "\n",
    "delta_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Delta Snapshot Threads:',\n",
    ")    \n",
    "\n",
    "dbx_destinations = widgets.Dropdown(options=['null', 'deltalake', 'unitycatalog'],value='null',\n",
    "    description='Destinations:',\n",
    ")\n",
    "dbx_staging = widgets.Dropdown(options=['dbfs'],value='dbfs',\n",
    "    description='Staging:',\n",
    ")\n",
    "\n",
    "sparse_cnt = widgets.BoundedIntText(value=1,min=1,max=100,\n",
    "    description='Table Cnt:',\n",
    ")\n",
    "sparse_fieldcount = widgets.BoundedIntText(value=50,min=0,max=9000,\n",
    "    description='# of Fields:',\n",
    ")\n",
    "sparse_fieldlength = widgets.BoundedIntText(value=10,min=1,max=1000,\n",
    "    description='Field Len:',\n",
    ")\n",
    "\n",
    "sparse_tps = widgets.BoundedIntText(value=1,min=0,max=1000,\n",
    "    description='TPS:',\n",
    ")\n",
    "sparse_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Threads:',\n",
    ")\n",
    "sparse_recordcount = widgets.Text(value=\"1M\",\n",
    "    description='Rec Cnt:',\n",
    ")\n",
    "\n",
    "sparse_fillpct = widgets.IntRangeSlider(value=[0,0],min=0,max=100,step=1,\n",
    "    description='Fill Range:', orientation='horizontal', readout=False\n",
    ")\n",
    "\n",
    "dense_cnt = widgets.BoundedIntText(value=1,min=1,max=100,\n",
    "    description='Table Cnt:',\n",
    ")\n",
    "dense_fieldcount = widgets.BoundedIntText(value=10,min=0,max=9000,\n",
    "    description='# of Fields:',\n",
    ")\n",
    "dense_fieldlength = widgets.BoundedIntText(value=100,min=1,max=1000,\n",
    "    description='Field Len:',\n",
    ")\n",
    "dense_recordcount = widgets.Text(value=\"100K\",\n",
    "    description='Rec Cnt:',\n",
    ")\n",
    "\n",
    "dense_tps = widgets.BoundedIntText(value=1,min=0,max=1000,\n",
    "    description='TPS:',\n",
    ")\n",
    "dense_threads = widgets.BoundedIntText(value=1,min=1,max=8,\n",
    "    description='Threads:',\n",
    ")\n",
    "\n",
    "dense_fillpct = widgets.IntRangeSlider(value=[0,100],min=0,max=100,step=1,\n",
    "    description='Fill Range:', orientation='horizontal', readout=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customize schema and size\n",
    "\n",
    "Existing tables will be appended with additional rows if the `Fill Range` is the same.  \n",
    "Increase the `Table Count` to create additional tables.  \n",
    "\n",
    "The following options are available:\n",
    "- Table count (Table Cnt): The number of tables to create.  \n",
    "  - Table names are `ycsbdense`, `ycsbdense2`, `ycsbdense3`, ... and `ycssparse`, `ycsbdense2`, and `ycsbdense3` ...\n",
    "- Number of Fields (# of Fields): The number of fields per table.  \n",
    "  - The field names are `FIELD0`, `FIELD1`, `FIELD2`, ...\n",
    "  - Note the use of `K`,`M`,`B` ... suffix at the end.\n",
    "- Field Length (Field Len): The length of random character data populated per field.  \n",
    "  - Note the use of `K`,`M`,`B` ... suffix at the end.\n",
    "- Record Count (Rec Cnt): The number of records per table generated.\n",
    "  - Note the use of `K`,`M`,`B` ... suffix at the end.\n",
    "- Fill Range: The relative start and end range of fields that are populated with data.  Be default: \n",
    "    - sparse tables are all NULLs by having the fill range be 0% to 0% ranges\n",
    "    - dense tables have all fields populated by having the fill range be 0% to 100% of ranges \n",
    "\n",
    "```sql\n",
    "[localhost][arcsrc] 1> \\describe ycsbsparse\n",
    "+-------------+-------------+-----------+-------------+----------------+-------------+\n",
    "| TABLE_SCHEM | COLUMN_NAME | TYPE_NAME | COLUMN_SIZE | DECIMAL_DIGITS | IS_NULLABLE |\n",
    "+-------------+-------------+-----------+-------------+----------------+-------------+\n",
    "| dbo         | YCSB_KEY    | int       |          10 |              0 | NO          |\n",
    "| dbo         | FIELD0      | text      |  2147483647 |         [NULL] | YES         |\n",
    "| dbo         | FIELD1      | text      |  2147483647 |         [NULL] | YES         |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c01c6f50ce449da8720e90bd87c8da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Sparse'), BoundedIntText(value=1, description='Table Cnt:', min=1),…"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show YCSB Data Controls\n",
    "VBox([HBox([Label('Sparse'), sparse_cnt, sparse_fieldcount, sparse_fieldlength, sparse_recordcount, sparse_fillpct]),\n",
    "    HBox([Label('Dense'),  dense_cnt, dense_fieldcount, dense_fieldlength, dense_recordcount, dense_fillpct])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SQL Server user, create and load YCSB data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense=(0, 100)\n",
      "sparse=(0, 0)\n",
      "replicant\n",
      "24.01.25.1 24.01\n",
      "PATH=/opt/stage/bin/jsqsh-dist-3.0-SNAPSHOT/bin added\n",
      "Msg 15025, Level 16, State 1, Server ron, Line 2\n",
      "The server principal 'arcsrc' already exists.\n",
      "Msg 1801, Level 16, State 3, Server ron, Line 1\n",
      "Database 'arcsrc' already exists. Choose a different database name.\n",
      "Changed database context to 'arcsrc'.\n",
      "Msg 15023, Level 16, State 5, Server ron, Line 1\n",
      "User, group, or role 'arcsrc' already exists in the current database.\n",
      "Starting type=sparse inst=1\n",
      "skip table create\n",
      "skip load need existing count 1000000 -gt 1100000 && field 50 -eq 50 \n",
      "Starting type=dense inst=1\n",
      "skip table create\n",
      "skip load need existing count 100000 -gt 100000 && field 10 -eq 10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "schema dump at /tmp/schema_dump.csv\n",
      "table count at /tmp/list_table_counts.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='. ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \\n    create_user;\\n    y_fieldcount=50 \\n    y_fieldlength=10  \\n    y_recordcount=1M \\n    y_fillstart=0      \\n    y_fillend=0      \\n    load_sparse_data_cnt 1;\\n    y_fieldcount=10 \\n    y_fieldlength=100 \\n    y_recordcount=100K \\n    y_fillstart=0      \\n    y_fillend=10      \\n    load_dense_data_cnt 1;\\n    dump_schema;\\n    list_table_counts', returncode=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"dense={dense_fillpct.value}\")\n",
    "print(f\"sparse={sparse_fillpct.value}\")\n",
    "\n",
    "# run load_sparse_data_cnt and load_dense_data_cnt \n",
    "subprocess.run(f\"\"\". ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \n",
    "    create_user;\n",
    "    y_fieldcount={sparse_fieldcount.value} \n",
    "    y_fieldlength={sparse_fieldlength.value}  \n",
    "    y_recordcount={sparse_recordcount.value} \n",
    "    y_fillstart={math.ceil((sparse_fillpct.value[0] * sparse_fieldcount.value) / 100)}      \n",
    "    y_fillend={int((sparse_fillpct.value[1] * sparse_fieldcount.value) / 100)}      \n",
    "    load_sparse_data_cnt {sparse_cnt.value};\n",
    "    y_fieldcount={dense_fieldcount.value} \n",
    "    y_fieldlength={dense_fieldlength.value} \n",
    "    y_recordcount={dense_recordcount.value} \n",
    "    y_fillstart={math.ceil((dense_fillpct.value[0] * dense_fieldcount.value) / 100)}      \n",
    "    y_fillend={int((dense_fillpct.value[1] * dense_fieldcount.value) / 100)}      \n",
    "    load_dense_data_cnt {dense_cnt.value};\n",
    "    dump_schema;\n",
    "    list_table_counts\"\"\",\n",
    "    shell=True,executable=\"/usr/bin/bash\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run YCSB and Arcion in the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start/Restart YCSB workload at 1 TPS\n",
    "\n",
    "Choose the options in the UI and run the cell below it to start the workload (YCSB).  \n",
    "\n",
    "\n",
    "YCSB update (workload A) controls for Dense and Sparse table groups separated. Each group has a separate control.  However, all of the tables in the group use the same controls.  \n",
    "1. Each table's TPS (throughput per second)\n",
    "   1. 0=fast as possible\n",
    "   2. 1=1 TPS\n",
    "   3. 10=10 TPS\n",
    "2. Each table's threads (concurrency) used to achieve the desired TPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc8cebb518743e19e43ad2f4b83baaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Sparse'), BoundedIntText(value=1, description='TPS:', max=1000), Bo…"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show YCSB run controls\n",
    "VBox([HBox([Label('Sparse'), sparse_tps, sparse_threads]), HBox([Label('Dense'),  dense_tps, dense_threads])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replicant\n",
      "24.01.25.1 24.01\n",
      "PATH=/opt/stage/bin/jsqsh-dist-3.0-SNAPSHOT/bin added\n",
      "running ycsb on /tmp/list_table_counts.csv\n",
      "YCSBDENSE,10,99999,10\n",
      "table_name=ycsbdense tabletype=dense record_count=100000 field_count=10 _y_threads=4 _y_target=3 _y_fieldlength=100\n",
      "ycsb ycsbdense pid 1459384\n",
      "ycsb ycsbdense log is at /home/rslee/github/dbx/ingestion/demo/sqlserver/logs/ycsb.ycsbdense.log\n",
      "ycsb ycsbdense can be killed with . ./demo/sqlserver/run-ycsb-sqlserver-source.sh; kill_ycsb)\n",
      "YCSBSPARSE,0,999999,50\n",
      "table_name=ycsbsparse tabletype=sparse record_count=1000000 field_count=50 _y_threads=2 _y_target=1 _y_fieldlength=10\n",
      "ycsb ycsbsparse pid 1459390\n",
      "ycsb ycsbsparse log is at /home/rslee/github/dbx/ingestion/demo/sqlserver/logs/ycsb.ycsbsparse.log\n",
      "ycsb ycsbsparse can be killed with . ./demo/sqlserver/run-ycsb-sqlserver-source.sh; kill_ycsb)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='. ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \\n    kill_ycsb;\\n    y_target_sparse=1 \\n    y_target_dense=3 \\n    y_threads_sparse=2 \\n    y_threads_dense=4 \\n    y_fieldlength_sparse=10 \\n    y_fieldlength_dense=100 \\n    start_ycsb;', returncode=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start/restart YCSB run\n",
    "subprocess.run(f\"\"\". ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \n",
    "    kill_ycsb;\n",
    "    y_target_sparse={sparse_tps.value} \n",
    "    y_target_dense={dense_tps.value} \n",
    "    y_threads_sparse={sparse_threads.value} \n",
    "    y_threads_dense={dense_threads.value} \n",
    "    y_fieldlength_sparse={sparse_fieldlength.value} \n",
    "    y_fieldlength_dense={dense_fieldlength.value} \n",
    "    start_ycsb;\"\"\",\n",
    "    shell=True,executable=\"/usr/bin/bash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Arcion\n",
    "\n",
    "Choose the options in the UI and run the cell below it to start the replication.  \n",
    "\n",
    "The following control are avail in the demo.  \n",
    "- Arcion - replication type and CDC methods  \n",
    "- Threads - control the parallelism.\n",
    "- Target - null, unity catalog or delta lake\n",
    "\n",
    "NOTE: Full mode does not work at this time.\n",
    "\n",
    "For SQL Server, change tracking, cdc are available for demo.  \n",
    "\n",
    "Performance is mainly controlled by the thread count by the extract and apply process.\n",
    "Additional controls are customizable via modifying the YAML files directly below.\n",
    "- [CDC YAML files](./demo/sqlserver/yaml/cdc/)\n",
    "- [Change Tracking YAML files](./demo/sqlserver/yaml/change/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35f330ace594a03a6fda3fc7d28d01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Arcion'), Dropdown(description='Replication:', options=('snapshot',…"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show Arcion controls\n",
    "VBox([\n",
    "      HBox([Label('Arcion'), repl_mode, cdc_mode]),\n",
    "      HBox([Label('Threads'), snapshot_threads, realtime_threads, delta_threads]),\n",
    "      HBox([Label('Target'), dbx_destinations, dbx_staging]),\n",
    "      ])\n",
    "\n",
    "# cluster where the notebook is running to auto populate the destinations\n",
    "spark_url=\"\"\n",
    "databricks_url=\"\"\n",
    "try:\n",
    "    cluster_id = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterId\")\n",
    "    workspace_id =spark.conf.get(\"spark.databricks.clusterUsageTags.clusterOwnerOrgId\")\n",
    "\n",
    "    # clusterName = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterName\")\n",
    "\n",
    "    workspaceUrl = spark.conf.get(\"spark.databricks.workspaceUrl\") # host name\n",
    "\n",
    "    http_path = f\"sql/protocolv1/o/{workspace_id}/{cluster_id}\"\n",
    "\n",
    "    spark_url=f\"jdbc:spark://{workspaceUrl}:443/default;transportMode=http;ssl=1;httpPath={http_path};AuthMech=3\"\n",
    "    databricks_url=f\"jdbc:databricks://{workspaceUrl}:443/default;transportMode=http;ssl=1;httpPath={http_path};AuthMech=3\"\n",
    "except:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change snapshot\n",
      "replicant\n",
      "24.01.25.1 24.01\n",
      "PATH=/opt/stage/bin/jsqsh-dist-3.0-SNAPSHOT/bin added\n",
      "/home/rslee/github/dbx/ingestion/demo/sqlserver\n",
      "enable change tracking on database arcsrc\n",
      "skip ALTER DATABASE arcsrc SET CHANGE_TRACKING = ON  (CHANGE_RETENTION = 2 DAYS, AUTO_CLEANUP = ON);\n",
      "skip ALTER TABLE replicate_io_audit_ddl ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE replicate_io_audit_tbl_cons ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE replicate_io_audit_tbl_schema ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE YCSBDENSE ENABLE CHANGE_TRACKING;\n",
      "skip ALTER TABLE YCSBSPARSE ENABLE CHANGE_TRACKING;\n",
      "replicant\n",
      "arcion pid 1477568\n",
      "arcion log is at /home/rslee/github/dbx/ingestion/demo/sqlserver/logs/arcion.log\n",
      "arcion can be killed with . ./demo/sqlserver/run-ycsb-sqlserver-source.sh; kill_arcion)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='. ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \\n    echo $PROG_DIR;\\n    cd $PROG_DIR;\\n    kill_arcion;\\n    a_repltype=snapshot \\n    SRCDB_SNAPSHOT_THREADS=1 \\n    SRCDB_REALTIME_THREADS=1 \\n    SRCDB_DELTA=1_THREADS\\n    DSTDB_TYPE=null\\n    DSTDB_STAGE=dbfs\\n    DSTDB_UNITY_URL=\\n    DSTDB_DBX_URL=\\n    start_change_arcion;', returncode=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start/restart Arcion\n",
    "print (f\"\"\"{cdc_mode.value} {repl_mode.value}\"\"\")\n",
    "subprocess.run(f\"\"\". ./demo/sqlserver/run-ycsb-sqlserver-source.sh; \n",
    "    echo $PROG_DIR;\n",
    "    cd $PROG_DIR;\n",
    "    kill_arcion;\n",
    "    a_repltype={repl_mode.value} \n",
    "    SRCDB_SNAPSHOT_THREADS={snapshot_threads.value} \n",
    "    SRCDB_REALTIME_THREADS={realtime_threads.value} \n",
    "    SRCDB_DELTA={delta_threads.value}_THREADS\n",
    "    DSTDB_TYPE={dbx_destinations.value}\n",
    "    DSTDB_STAGE={dbx_staging.value}\n",
    "    DSTDB_UNITY_URL={databricks_url}\n",
    "    DSTDB_DBX_URL={spark_url}\n",
    "    start_{cdc_mode.value}_arcion;\"\"\",\n",
    "    shell=True,executable=\"/usr/bin/bash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
